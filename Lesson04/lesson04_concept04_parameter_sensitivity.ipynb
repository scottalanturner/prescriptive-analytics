{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameter Sensitivity: Small Errors Can Cause Large Problems\n",
        "\n",
        "This notebook demonstrates a critical insight: **small errors in parameters can lead to large errors in recommendations**.\n",
        "\n",
        "Understanding this is essential because:\n",
        "- Parameters are estimates, not facts\n",
        "- Small parameter errors don't always cause small recommendation errors\n",
        "- Models can be sensitive to parameters\n",
        "- Testing sensitivity helps assess recommendation risk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts\n",
        "\n",
        "**Parameter Sensitivity**:\n",
        "- How much does the recommendation change when a parameter changes?\n",
        "- Some parameters have large effects, others have small effects\n",
        "- Understanding sensitivity helps identify which parameters matter most\n",
        "\n",
        "**Small Errors → Large Errors**:\n",
        "- A 5% error in a parameter might cause a 20% error in the recommendation\n",
        "- This happens because models optimize based on parameters\n",
        "- Small parameter changes can shift the optimal solution\n",
        "\n",
        "**Uncertainty Affects Confidence**:\n",
        "- High uncertainty in parameters → Low confidence in recommendations\n",
        "- Low uncertainty in parameters → Higher confidence in recommendations\n",
        "- You cannot have high confidence when parameters have high uncertainty\n",
        "\n",
        "**Critical insight**: Test sensitivity to understand how parameter errors affect recommendations. This helps assess risk.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario: Staffing Decision with Uncertain Parameters\n",
        "\n",
        "You manage a call center and must decide how many agents to schedule. The model uses several parameters with different levels of uncertainty:\n",
        "\n",
        "- **Average call duration**: 5 minutes (could be 4-6 minutes) - Medium uncertainty\n",
        "- **Call arrival rate**: 10 calls/hour (could be 8-12 calls/hour) - High uncertainty  \n",
        "- **Agent cost**: $25/hour (from payroll - Low uncertainty)\n",
        "\n",
        "**Question**: How sensitive is the recommendation to parameter errors? What happens if parameters are wrong?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Base Case Model\n",
        "\n",
        "Let's start with the base case using estimated parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base case parameters (estimates with uncertainty)\n",
        "avg_call_duration = 5.0  # minutes (could be 4-6)\n",
        "call_arrival_rate = 10.0  # calls/hour (could be 8-12)\n",
        "agent_cost = 25.0  # $/hour (from payroll - reliable)\n",
        "\n",
        "# Model calculation: How many agents needed?\n",
        "# Each agent can handle: 60 minutes / avg_call_duration calls per hour\n",
        "calls_per_agent_per_hour = 60 / avg_call_duration\n",
        "\n",
        "# Agents needed = call_arrival_rate / calls_per_agent_per_hour\n",
        "agents_needed_base = call_arrival_rate / calls_per_agent_per_hour\n",
        "agents_needed_base = np.ceil(agents_needed_base)  # Round up\n",
        "\n",
        "# Total cost\n",
        "total_cost_base = agents_needed_base * agent_cost\n",
        "\n",
        "print(\"BASE CASE (Using Estimated Parameters):\")\n",
        "print(f\"  Average call duration: {avg_call_duration} minutes (estimate, could be 4-6)\")\n",
        "print(f\"  Call arrival rate: {call_arrival_rate} calls/hour (estimate, could be 8-12)\")\n",
        "print(f\"  Agent cost: ${agent_cost}/hour (from payroll - reliable)\")\n",
        "print(f\"\\nMODEL RECOMMENDATION:\")\n",
        "print(f\"  Agents needed: {agents_needed_base:.0f}\")\n",
        "print(f\"  Total cost: ${total_cost_base:.0f}/hour\")\n",
        "print(f\"\\n⚠️  WARNING: Parameters have uncertainty - recommendation has uncertainty too!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Test Parameter Sensitivity\n",
        "\n",
        "Let's test what happens when parameters are wrong. This shows sensitivity:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different parameter values\n",
        "sensitivity_tests = []\n",
        "\n",
        "# Test 1: Call duration varies\n",
        "for duration in [4.0, 4.5, 5.0, 5.5, 6.0]:\n",
        "    calls_per_agent = 60 / duration\n",
        "    agents = np.ceil(call_arrival_rate / calls_per_agent)\n",
        "    cost = agents * agent_cost\n",
        "    change_pct = ((cost - total_cost_base) / total_cost_base) * 100\n",
        "    param_error = ((duration - avg_call_duration) / avg_call_duration) * 100\n",
        "    \n",
        "    sensitivity_tests.append({\n",
        "        'Parameter': 'Call Duration',\n",
        "        'Param Value': duration,\n",
        "        'Param Error %': f\"{param_error:+.0f}%\",\n",
        "        'Agents': agents,\n",
        "        'Cost': cost,\n",
        "        'Cost Change %': f\"{change_pct:+.1f}%\"\n",
        "    })\n",
        "\n",
        "# Test 2: Arrival rate varies\n",
        "for arrival in [8.0, 9.0, 10.0, 11.0, 12.0]:\n",
        "    calls_per_agent = 60 / avg_call_duration\n",
        "    agents = np.ceil(arrival / calls_per_agent)\n",
        "    cost = agents * agent_cost\n",
        "    change_pct = ((cost - total_cost_base) / total_cost_base) * 100\n",
        "    param_error = ((arrival - call_arrival_rate) / call_arrival_rate) * 100\n",
        "    \n",
        "    sensitivity_tests.append({\n",
        "        'Parameter': 'Arrival Rate',\n",
        "        'Param Value': arrival,\n",
        "        'Param Error %': f\"{param_error:+.0f}%\",\n",
        "        'Agents': agents,\n",
        "        'Cost': cost,\n",
        "        'Cost Change %': f\"{change_pct:+.1f}%\"\n",
        "    })\n",
        "\n",
        "sensitivity_df = pd.DataFrame(sensitivity_tests)\n",
        "print(\"PARAMETER SENSITIVITY ANALYSIS:\\n\")\n",
        "print(sensitivity_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\nKEY OBSERVATIONS:\")\n",
        "print(\"  - Small parameter errors can cause large cost changes\")\n",
        "print(\"  - Model is sensitive to both parameters\")\n",
        "print(\"  - A 10% parameter error can cause >10% cost change!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Call duration sensitivity\n",
        "duration_tests = [t for t in sensitivity_tests if t['Parameter'] == 'Call Duration']\n",
        "durations = [t['Param Value'] for t in duration_tests]\n",
        "costs_duration = [t['Cost'] for t in duration_tests]\n",
        "\n",
        "ax1 = axes[0]\n",
        "ax1.plot(durations, costs_duration, 'o-', color='blue', linewidth=2, markersize=8)\n",
        "ax1.axhline(y=total_cost_base, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Base Cost = ${total_cost_base:.0f}')\n",
        "ax1.axvline(x=avg_call_duration, color='green', linestyle='--', linewidth=1, alpha=0.5)\n",
        "ax1.set_xlabel('Call Duration (minutes)', fontsize=11)\n",
        "ax1.set_ylabel('Total Cost ($/hour)', fontsize=11)\n",
        "ax1.set_title('Sensitivity to Call Duration\\nSmall parameter change → Large cost change', \n",
        "              fontsize=12, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Arrival rate sensitivity\n",
        "arrival_tests = [t for t in sensitivity_tests if t['Parameter'] == 'Arrival Rate']\n",
        "arrivals = [t['Param Value'] for t in arrival_tests]\n",
        "costs_arrival = [t['Cost'] for t in arrival_tests]\n",
        "\n",
        "ax2 = axes[1]\n",
        "ax2.plot(arrivals, costs_arrival, 's-', color='orange', linewidth=2, markersize=8)\n",
        "ax2.axhline(y=total_cost_base, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Base Cost = ${total_cost_base:.0f}')\n",
        "ax2.axvline(x=call_arrival_rate, color='green', linestyle='--', linewidth=1, alpha=0.5)\n",
        "ax2.set_xlabel('Call Arrival Rate (calls/hour)', fontsize=11)\n",
        "ax2.set_ylabel('Total Cost ($/hour)', fontsize=11)\n",
        "ax2.set_title('Sensitivity to Arrival Rate\\nSmall parameter change → Large cost change', \n",
        "              fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHT:\")\n",
        "print(\"  - Both parameters show high sensitivity\")\n",
        "print(\"  - Small parameter errors cause large cost changes\")\n",
        "print(\"  - This is why parameter accuracy matters!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Uncertainty Affects Confidence\n",
        "\n",
        "Let's see how parameter uncertainty affects our confidence in the recommendation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameter uncertainty levels\n",
        "parameters = pd.DataFrame({\n",
        "    'Parameter': ['Call Duration', 'Arrival Rate', 'Agent Cost'],\n",
        "    'Base Value': [avg_call_duration, call_arrival_rate, agent_cost],\n",
        "    'Uncertainty': ['±20% (4-6 min)', '±20% (8-12 calls/hr)', '±0% (from payroll)'],\n",
        "    'Uncertainty Level': ['Medium', 'High', 'Low']\n",
        "})\n",
        "\n",
        "print(\"PARAMETER UNCERTAINTY:\\n\")\n",
        "print(parameters.to_string(index=False))\n",
        "\n",
        "# Calculate confidence based on uncertainty\n",
        "# High uncertainty in key parameters = Low confidence\n",
        "max_uncertainty = 'High'  # Arrival rate has high uncertainty\n",
        "if max_uncertainty == 'High':\n",
        "    confidence = 'Low'\n",
        "elif max_uncertainty == 'Medium':\n",
        "    confidence = 'Medium'\n",
        "else:\n",
        "    confidence = 'High'\n",
        "\n",
        "print(f\"\\n\\nCONFIDENCE ASSESSMENT:\")\n",
        "print(f\"  Highest uncertainty: {max_uncertainty} (Arrival Rate)\")\n",
        "print(f\"  Overall confidence in recommendation: {confidence}\")\n",
        "print(f\"  Reason: You cannot have high confidence when key parameters have high uncertainty\")\n",
        "\n",
        "# Visualize uncertainty and confidence\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "uncertainty_colors = {'Low': 'green', 'Medium': 'orange', 'High': 'red'}\n",
        "colors = [uncertainty_colors.get(level, 'gray') for level in parameters['Uncertainty Level']]\n",
        "\n",
        "bars = ax.barh(parameters['Parameter'], parameters['Base Value'], color=colors, edgecolor='black')\n",
        "ax.set_xlabel('Parameter Value', fontsize=11)\n",
        "ax.set_title('Parameter Uncertainty Levels\\nGreen=Low, Orange=Medium, Red=High', \n",
        "             fontsize=12, fontweight='bold')\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add uncertainty labels\n",
        "for i, (bar, unc) in enumerate(zip(bars, parameters['Uncertainty'])):\n",
        "    ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
        "            f\"({unc})\", va='center', fontsize=9, style='italic')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\\nPRACTICAL IMPLICATION:\")\n",
        "print(f\"  - Recommendation: Schedule {agents_needed_base:.0f} agents\")\n",
        "print(f\"  - Confidence: {confidence} (due to parameter uncertainty)\")\n",
        "print(f\"  - Action: Test sensitivity, consider ranges, build in buffers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Parameter Sensitivity\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "1. **Small parameter errors can cause large recommendation errors**\n",
        "   - A 5% parameter error might cause a 20% recommendation error\n",
        "   - Models optimize based on parameters, so errors propagate\n",
        "   - You cannot assume small errors have small effects\n",
        "\n",
        "2. **Models can be sensitive to parameters**\n",
        "   - Some parameters have large effects on recommendations\n",
        "   - Understanding sensitivity helps identify which parameters matter most\n",
        "   - Test sensitivity to understand risk\n",
        "\n",
        "3. **Uncertainty affects confidence**\n",
        "   - High uncertainty in parameters → Low confidence in recommendations\n",
        "   - Low uncertainty in parameters → Higher confidence\n",
        "   - You cannot have high confidence when parameters have high uncertainty\n",
        "\n",
        "4. **Practical implications**\n",
        "   - Test sensitivity: What if parameters are wrong?\n",
        "   - Identify which parameters matter most\n",
        "   - Build robustness into recommendations\n",
        "   - Adjust confidence based on parameter uncertainty\n",
        "\n",
        "**Remember**: Parameters are estimates. Test sensitivity to understand how parameter errors affect recommendations!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
